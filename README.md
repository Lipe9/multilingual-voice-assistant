ü§ñ Voice-to-Voice AI Assistant (Whisper + GPT + gTTS)
Este projeto consiste em um assistente virtual capaz de ouvir, processar e responder comandos de voz em m√∫ltiplos idiomas. A solu√ß√£o integra tr√™s tecnologias pilares da Intelig√™ncia Artificial moderna para criar uma experi√™ncia de conversa√ß√£o fluida e natural.

üéØ Objetivo do Projeto
Desenvolver um pipeline completo de Conversa√ß√£o por Voz (Voice-to-Voice), demonstrando a integra√ß√£o de modelos de Reconhecimento de Fala (ASR), Processamento de Linguagem Natural (NLP) e S√≠ntese de Voz (TTS).

üß© Como funciona?
O sistema opera em um fluxo de quatro est√°gios principais:

Speech-to-Text (STT): O √°udio do usu√°rio √© capturado e processado pelo OpenAI Whisper. Diferente de outros motores de busca, o Whisper √© robusto contra ru√≠dos e entende sotaques t√©cnicos de forma excepcional.

L√≥gica e Intelig√™ncia (LLM): O texto transcrito √© enviado para a API do ChatGPT (GPT-3.5/4). Aqui, a IA interpreta a inten√ß√£o, busca a resposta ou realiza a tradu√ß√£o necess√°ria.

Text-to-Speech (TTS): A resposta textual √© convertida em √°udio pelo Google Text-to-Speech (gTTS), gerando um arquivo de sa√≠da amig√°vel.

Interface de Sa√≠da: O sistema reproduz o arquivo final, permitindo uma conversa sem necessidade de teclado.

üõ†Ô∏è Tecnologias e Ferramentas
Linguagem: Python 3.10+

Transcri√ß√£o: OpenAI Whisper (Local ou via API)

C√©rebro: OpenAI Chat Completions API

Voz: gTTS (Google Text-to-Speech)

Gest√£o de Ambiente: Python-dotenv (para prote√ß√£o de API Keys)

üöÄ Destaques T√©cnicos
Suporte Multilingue: O sistema detecta automaticamente o idioma falado.

Seguran√ßa: Implementa√ß√£o de vari√°veis de ambiente para evitar vazamento de credenciais no GitHub.

Modularidade: C√≥digo organizado em fun√ß√µes para facilitar a troca de modelos (ex: trocar gTTS pelas vozes da ElevenLabs ou OpenAI Speech).
